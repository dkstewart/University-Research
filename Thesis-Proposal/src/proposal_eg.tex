\chapter{Proposed Approach}
\label{ch:prop}
The idea of inductive validity cores was introduced in Chapter \ref{ch:intro}.
This idea is applicable to the context of symbolic model checking using inductive proof methods. The idea is, after proving the correctness of a given property, to extract a minimal portion of the system (model) necessary for the proof of the property. In other words, we would like to determine why the property is satisfied by the system. Since this information is obtained from the inductive proofs, we call it \emph{inductive} validity core. With minimal IVCs, we are able to abstract away the part of the system irrelevant to the proof of the property.

This chapter, first, mentions some required background, then provides a formal description of the IVC notion. Using this formalization, we explain how IVCs can be used in traceability and adequacy checking.

\section{Background}

\newcommand{\satisfies}{\vdash_{\!\!s}}
\newcommand{\nsatisfies}{\nvdash_{\!\!s}}
\newcommand{\bool}[0]{\mathit{bool}}
\newcommand{\reach}[0]{\mathit{R}}
\newcommand{\ite}[3]{\mathit{if}\ {#1}\ \mathit{then}\ {#2}\ \mathit{else}\ {#3}}
\newcommand{\ivc}{\textit{IVC}}
\newcommand{\mivc}{\textit{MIVC}}

This section presents formalizations of transition systems, inductive validity cores, and background information on mutation-based coverage metrics.  Although we focus the formalism below on safety properties, the approach is able to handle liveness properties through reduction to safety properties, as is performed by, e.g., K-liveness.

Given a state space $U$, a transition system $(I,T)$ consists of an
initial state predicate $I : U \to \bool$ and a transition step
predicate $T : U \times U \to \bool$. We define the notion of
reachability for $(I, T)$ as the smallest predicate $\reach : U \to
\bool$ which satisfies the following formulas:
\begin{gather*}
  \forall s.~ I(u) \Rightarrow \reach(u) \\
  \forall u, u'.~ \reach(u) \land T(u, u') \Rightarrow \reach(u')
\end{gather*}
A safety property $P : U \to \bool$ is a state predicate that holds on a transition system $(I, T)$ if it holds on all
reachable states, i.e., $\forall u.~ \reach(u) \Rightarrow P(u)$,
written as $\reach \Rightarrow P$ for short. When this is the case, we
write $(I, T)\vdash P$. We assume the transition relation has the structure of a top-level conjunction. This assumption gives us a structure that we can easily manipulate. Given $T(u, u') = T_1(u, u') \land \cdots \land T_n(u, u')$ we will write $T = T_1 \land \cdots \land T_n$ for short.
By further abuse of notation,
$T$ is identified with the set of its top-level conjuncts. Thus, $x \in
T$ means that $x$ is a top-level conjunct of $T$, and $S
\subseteq T$ means all top-level conjuncts of $S$ are top-level
conjuncts of $T$. When a top-level conjunct $x$ is removed from $T$, it is written as $T \setminus \{x\}$.


%\begin{definition}{\emph{Inductive Validity Core:}}
%  \label{def:ivc}
%  Given $(I, T)\vdash P$, $S \subseteq
%  T$ is an {\em Inductive Validity Core} for $P$
%  \emph{iff} $(I, S) \vdash P$.
%\end{definition}
%
%In examining provability, we are interested in {\em minimal} sets that satisfy a property $P$; tracing a property to the entire model is not particularly enlightening.
\section{Inductive Validity Cores}

\begin{definition}{\emph {Inductive Validity Core (\ivc):}}
  \label{def:ivc}
  $S \subseteq T$ for $(I, T)\vdash P$ is an Inductive Validity Core,
  denoted by $\ivc(P, S)$, iff $(I, S) \vdash P $.
\end{definition}

In examining provability, we are interested in minimal sets
that satisfy a property P; tracing a property to the entire model
is not particularly enlightening.  Fortunately, \ivc s have
the following monotonicity property: given $(I, T)\vdash P$, $\forall S_1 \subseteq S_2 \subseteq T$. $IVC(P, S_1) \Rightarrow IVC(P, S_2)$.  We next introduce the notion of {\em minimal} inductive validity cores.

\begin{definition}{\emph{Minimal Inductive Validity Core (\mivc):}}
  \label{def:minimal-ivc}
  $S \subseteq T$ is a minimal Inductive Validity Core,
  denoted by $\mivc(P, S)$, iff ~$\ivc(P, S) \wedge \forall T_i \in S.~ (I, S\setminus\{ T_i \}) \nvdash P$.
\end{definition}

Note that given $(I, T) \vdash P$, $P$ always has at least one \mivc , which implies \mivc s are not necessarily unique.
For example, take $I = a \land b$, $T = a' \land b'$, and $P = a \lor
b$. Then both $\{a'\}$ and $\{b'\}$ are \mivc s for $(I, T)\vdash P$. To capture this fact, the \emph{all \mivc s ($AIVC$)} relation has been introduced \cite{Murugesan16:renext}.
$$ AIVC(P) \equiv  \{\ S~|~S \subseteq T \land  \mivc(P, S)\} $$
%In the example in Figure \ref{fig:asw}, as visualized in part (b),
%$AIVC ({\tt P}) = \{\{{\tt P}, {\tt c2}, {\tt c3}\}, \{{\tt P}, {\tt x}, {\tt c3}\}\}$.
\noindent

 %We adapt the recent work by Liffiton et al. \cite{marco2016fast} from the generation of MUSes from UNSAT-cores to all IVCs for inductive model checking.  This requires changing the underlying mechanisms that are used to construct candidate solutions and also changing the structure of the proof of correctness.  In addition, we demonstrate that the approach can terminate with all minimal IVCs even if the witness generator only generates approximately minimal IVCs (utilizing a ``fast''  algorithm for a single IVC computation).


\section{Traceability}
Given {\em all} proofs of a particular property, we are able to categorize the model elements based on \mivc ~and
$AIVC$ relations for $P$:

\begin{itemize}
\item $MUST (P) = \bigcap AIVC(P)$
\item $MAY(P) = (\bigcup AIVC (P)) \setminus MUST (P)$
\item $IRR(P) = T \setminus (\bigcup AIVC (P))$
\end{itemize}

\noindent This categorization helps to identify the role and relevance of each design element in satisfying a property. Function $MUST$ specifies the parts of the model absolutely necessary for the property satisfaction.  Any change to these parts will affect provability of the property. On the other hand, any single element in $MAY (P)$, may be modified without affecting satisfaction of $P$(though modifying multiple elements may require re-proof). The $IRR$ denotes model elements that are irrelevant to the validity of $P$.

The $AIVC$ set improves understanding of how a change in the requirement will affect the target artifacts and vice versa. While the $AIVC$ of a requirement gives a clear picture of various ways a requirement is satisfied by the system, the categorization of target artifacts helps precisely assess and plan when and where the changes have to be implemented. The $MUST$ elements are those target artifacts that are highly likely to change with any change in the requirement, whereas not all $MAY$ elements may need to be changed.

If a requirement has elements only in its $MAY$ set, that is if $MUST$ set is empty
($MUST(r) = \emptyset$), it indicates that the requirement has been (intentionally or unintentionally) implemented in independent ways, such as fault tolerant systems. For such requirements, one has to carefully analyze and decide if the target artifacts in all or one disjoint set needs to be changed. These analysis could be performed either from the perspective of one or all requirements of the system.

From the target artifact side, this categorization helps analyze the impact of changes to the artifact. Suppose we decide to change a target artifact in the $MAY$ set for a requirement. While one might think that it is safe to change this artifact since it does not affect that requirement's satisfaction, an examination of the $AIVC$ sets of other requirements helps identify if it is indeed safe to change that artifact. If it is present in the $MUST$ set for another requirement, then a change to this artifact will definitely impact the other requirement. However, if it is in the $MAY$ sets for all the requirements, then it is clearly safe to change. Hence, this categorization helps us to assess critical dependencies between the target artifacts and the satisfaction of requirements and thus enables a precise bi-directional impact analysis of a change.

Complete traceability can assist in tailoring verification and validation in systems. For instance, if several requirements have a certain target artifact in their $MUST$ set, say an particular assumption, it reveals the importance of focusing V\&V attention on that artifact. Along the same lines, for a system with a complex architecture (components that each have functionality) such as  system of systems, this categorization helps identify components that is critical to satisfy most requirements. This categorization helps plan verification strategies.

\section{Coverage Metrics in Formal Verification}


Given this representation, it is possible to discuss mutations of a single vertex: either stuck-at-zero, stuck-at-one, or nondeterministic.  This mutation is performed by changing the vertex to , where can be a ``fresh'' input for \emph{non-deterministic mutations}, or fixed to 0 or 1 for stuck-at mutations. Formally the semantics of a mutant net-list is defined as a new labeling function:
%To mutate a vertex $v_i$, a  multiplexer is added to $N$. Then, the  edges  of  the  net-list are modified such  that  the  tails  of  all  the edges directed from
%$v_i$ are changed to the output of the multiplexer, which replaces
%$E_N$ with a new set of edges $E^{v_i}_M$ in the mutated net-list.
Let  $N = (V_N,E_N, \tau_N)$ be the original net-list; to mutate a vertex $v_i$ using $\tau^{v_i}_{N}$, the  edges that had tails pointing to $v_i$ are removed,
 which replaces $E_N$ with a new set of edges $E^{v_i}_M$ in the mutated net-list.
When property $P$ satisfied by $N$ fails on the mutant net-list $(V_N, E^{v_i}_N, \tau^{v_i}_{N})$, which is obtained from the \emph{non-deterministic} mutation of $v_i$, it is said that a mutant is discovered for $P$ (or $v_i$ is covered by $P$).
We assume a function $TR : N \rightarrow T$ that returns the corresponding transition relation of a net-list.
Given this representation, and the initial state $I$, we can define nondeterministic coverage as follows:


We propose a new approach for measuring property completeness based on proof rather than mutation.  We first define notation, then describe different possible metrics given a set of {\em minimal proofs}.%\footnote{Section~\ref{sec:impl} describes how these proofs are discovered in practice.}
%\subsection{Coverage and Minimal Proofs}
%Alternatively, we can consider using the proofs themselves as a mechanism for determining adequacy of requirements.


%For the sake of simplicity, we refer to the coverage function
%formalized in Definition \ref{d
%\footnote{\noindent ~Throughout the paper, when a coverage metric is justifiable, like \ivccov, we say that it preserves provability of the property.}
%Thus, the coverage score for \ivccov\ is often higher than the score for \nondetcov.


%As the variable is no longer constrained by a defining equation, it is effectively an %input.










