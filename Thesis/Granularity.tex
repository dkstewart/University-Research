\chapter{Granularity of Specifications}
\label{chap:granularity}
The specification of requirements is an important part the development of critical systems, and the analysis results are greatly dependent upon these specifications. Formal specification, as described in Section~\ref{sec:formalSpec}, is the translation of the informal system requirements into a mathematical logic ~\cite{hinchey2012industrial}. The informal system requirements are initially developed in natural language that is often ambiguous and always mathematically informal. The formal semantics of specified properties, such as LTL, is fully defined and, thus, is amenable to mathematical reasoning; this does not imply that formalization is fool-proof or straightforward to do~\cite{kotonya1998requirements}. 

 In the approach that we describe in this research, we define these specifications in the form of \emph{guarantees} of the behavior of components and \emph{assumptions} regarding the environment. The verification task is to show that a system guarantee $P_s$ is provable given the behavior of its subcomponents $C_s$ and the system assumption $A_s$. A systems engineer must translate natural language requirements into these formal contracts for each component. 
 
There are a number of difficulties inherent in this specification task. One challenge is the ambiguity of natural language. Another is writing the specification such that it is sufficiently {\em granular}: all subexpressions are relevant to the specification. As described in Chapter~\ref{chap:prelim}, a transition relation is considered to be a conjunction of Boolean formulas. Depending on how equations are specified in the model, it is possible that all of the equations are required to determine the validity of the properties. However, in certain cases, subexpressions of equations may be irrelevant. If the equation is decomposed into smaller pieces, this irrelevance becomes visible and the model is no longer completely {\em covered}. Simply put, coverage is a metric that determines how well properties cover the design of a model. It is often the case that splitting the equations into more conjuncts, or equivalently, making the model more granular, leads to lower coverage of the model. 
 
The reason this is of interest is due to the behavioral approach of fault analysis. In an assume-guarantee environment, as guarantees change granularity, the results of the fault analysis may also change. Previous work has shown that the specification and formulation of the guarantees can affect the IVC analysis results~\cite{ghassabani_2018}. The algorithm used to generate the cut sets at a single layer is based on MIVC results. Insufficiently granular specifications could lead to the loss of minimality with regard to the cut set. 

The intuition can be illustrated with a small example. Assuem the safety property $P$ is some formula $P = a$, and we wish to know the MIVCs for $P$. There are two supporting guarantees in the model, $g_1$ and $g_2$ which are elements of an MIVC. Let $g_1 = \mathit{if} b \mathit{then} a \mathit{else} c$, and $g_2 = b \land (c \lor d)$. While the guarantee $g_2$ is required for the proof of $P$, there is a subformula in $g_2$ that is entirely irrelevant: $c \lor d$. The IVCs in a more granular model would theoretically reflect only the necessary equations required for property verification, and, thus, would provide more specific analysis results. 

Because the minimal cut sets are derived from the MIVCs, any insufficiently granular results from the \aivcalg algorithm will be reflected in the fault analysis. To illustrate this idea, consider the example above. If two faults were to cause the subformula $c \lor d$ to evaluate to false, these faults would be reflected in the minimal cut sets, despite the subformula's irrelevance to the proof of the property. To better understand this problem, we explored the possibility of automatically refining the specifications in a model to allow for more granular specifications. This chapter outlines our exploration into this topic. 

\section{Background Research and Foundation}
%As described in Chapter~\ref{chap:prelim}, a transition relation is considered to be a conjunction of Boolean formulas. Depending on how contracts are specified in the model, it is possible to have a ``complete" specification, i.e., all of the equations in the model are required to determine the validity of the property. However, in certain cases, subexpressions of equations may be irrelevant. If the equation is decomposed into smaller pieces, this incompleteness becomes visible and the model is no longer completely {\em covered}. Simply put, coverage is a metric that determines how well properties cover the design of a model. It is often the case that splitting an equation of the model into more conjuncts, or equivalently, making the model more \textit{granular}, leads to lower coverage of the model. 

%This can be seen in the IVCs generated for a given safety property. The intuition can be illustrated with a small example. If the safety property is: $P : A $ for some complex formula $A$ and an equation in the model is $g: A \land (B \lor C)$, the supporting equation $g$ will be an IVC. But $g$ also contains other statements that do not necessarily support the proof of $P$ -- the only portion of $g$ that matters to the proof is $A$. The IVCs in a more granular model would theoretically reflect only the necessary equations required for property verification, and, thus, would provide more specific analysis results. A more granular model in this small example could be $g_1 : A$ and $g_2: B \lor C$. Then we would see only $g_1$ in the IVC elements for $P$. 

Similar work has been done in test case generation, specifically \emph{Modified Condition and Decision Coverage} (MC/DC). It was found that MC/DC over implementations with structurally complex Boolean expressions are generally larger and more effective than MC/DC over functionally equivalent but structurally simpler implementations~\cite{gay2016effect}. An automated technique called \emph{inlining} provides a restructuring of the model by inlining simpler Boolean expressions into a single, now more complex, expression. An example of an unlined implementation is: 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=1.0]{images/uninlinedEx.PNG}
	\end{center}
	\vspace{-1.5em}
	%\caption{Uninlined implementation example}
	%\label{fig:uninlined}
\end{figure}

And the associated inlined implementation is: 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=1.0]{images/inlined.PNG}
	\end{center}
	\vspace{-1.5em}
	%%\caption{Inlined implementation example}
%	\label{fig:inlined}
\end{figure}

Inlining results in a behaviorally equivalent implementation with different structure (syntax). The reason MC/DC provides better fault finding in terms of test case generation is because MC/DC on an inlined system will require specific combinations of input that will not be required to achieve coverage of the non-inlined system~\cite{gay2016effect}. 

Inductive validity cores, on the other hand, attempt to answer a different kind of question about the model than test coverage. In the IVC case, the goal is to find the minimal sets of model elements that contribute to a proof of a safety property. When these model elements are guarantees and assumptions, the \emph{granularity} of these logical statements matters in the opposite way. The IVC algorithm performs no deeper traces than those defined in those model elements (guarantees/assumptions). For our purposes, it is beneficial at times to see which subexpressions of the specification are necessary for the proof. Instead of making the equations more complex (inlining), we wish to simplify the equations (outlining). In this way, the IVCs are more specific with regard to which parts of the equation are vital to the proof. This will theoretically decompose the specifications and decrease property dependencies within the model. 

Granularity of contracts for IVCs has been briefly discussed by Ghassabani~\cite{ghassabani_2018}, but to our knowledge has not been discussed in any other previous work -- in particular related to minimal cut set generation. Since MIVC generation is a required step of our minimal cut set algorithms, it is important to discuss how the granularity of the model will affect the cut sets generated through this approach. 

As described in Chapter~\ref{chap:compFF}, the backend model checker used in this transformation is \jkind, which performs $k$-induction over the transition system and uses the dataflow programming language Lustre as input. Ghassabani performed a preliminary investigation of granularity within the context of the Lustre language. Lustre provides an adequate formalism for this discussion because it is top-level conjunctive, equational, and \textit{referentially transparent}~\cite{Halbwachs91:IEEE}. This means that the behavior of a Lustre program is defined by a system of equations and any subexpression on the right side of an equation can be extracted and assigned a fresh variable\footnote{A fresh variable is a variable with an identifier that has not been used within the program.} that is substituted into the original equation without changing the meaning of the program. In this context, \textit{granular refinement} is defined as an extraction of a subexpression into a new equation assigning a fresh variable. 


\input{GranularityEx}
\input{GranularityAlg}